{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2b98bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n",
      "<|im_start|>user\n",
      "What is gravity?<|im_end|>\n",
      "\n",
      "<|im_start|>system\n",
      "You are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n",
      "<|im_start|>user\n",
      "What is gravity?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Gravity is a fundamental force of nature that governs the behavior of objects in the universe. It is a force that attracts objects with mass towards each other, pulling them towards the center of the Earth. The force of gravity is a\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "checkpoint = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
    "\n",
    "device = \"cpu\" # for GPU usage or \"cpu\" for CPU usage\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "# for multiple GPUs install accelerate and do `model = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=\"auto\")`\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is gravity?\"}]\n",
    "input_text=tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "print(input_text)\n",
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs, max_new_tokens=50, temperature=0.2, top_p=0.9, do_sample=True)\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a154452",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an AI assistant with access to various tools.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi !\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi human, what can help you with ?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cbd2454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are an AI assistant with access to various tools.<|im_end|>\n",
      "<|im_start|>user\n",
      "Hi !<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi human, what can help you with ?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_chat = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "print(tokenizer.decode(tokenized_chat[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cc6ff30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are an AI assistant with access to various tools.<|im_end|>\n",
      "<|im_start|>user\n",
      "Hi !<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi human, what can help you with ?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "I'm here to assist you with any questions or issues you might have regarding your health or wellness. Whether you're looking for advice on managing stress, improving your diet, or simply seeking advice on how to improve your physical health, I'm here to help.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(tokenized_chat, max_new_tokens=128) \n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41b91fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are an AI assistant with access to various tools.<|im_end|>\n",
      "<|im_start|>user\n",
      "Hi !<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi human, what can help you with ?<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_chat = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=False, return_tensors=\"pt\")\n",
    "print(tokenizer.decode(tokenized_chat[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05671f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are an AI assistant with access to various tools.<|im_end|>\n",
      "<|im_start|>user\n",
      "Hi !<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi human, what can help you with ?<|im_end|>\n",
      "<|im_start|>user\n",
      "I'm having trouble with my code. I'm trying to find the maximum value in a list of integers. Here's my code:\n",
      "\n",
      "```python\n",
      "def find_max(lst):\n",
      "    max_val = lst[0]\n",
      "    for num in lst:\n",
      "        if num > max_val:\n",
      "            max_val = num\n",
      "    return max_val\n",
      "\n",
      "numbers = [12, 45, 7, 23, 56, 89, 34]\n",
      "print(find_max(numbers))\n",
      "```\n",
      "\n",
      "I'm getting the following error:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(tokenized_chat, max_new_tokens=128)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92022b68",
   "metadata": {},
   "source": [
    "The add_generation_prompt parameter adds tokens that indicate the start of a response. This ensures the chat model generates a system response instead of continuing a users message.\n",
    "You shouldnâ€™t use add_generation_prompt and continue_final_message together. The former adds tokens that start a new message, while the latter removes end of sequence tokens. Using them together returns an error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ccd3b6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
